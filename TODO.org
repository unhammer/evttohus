* TODO include anymalign results where src=fad in canonicalise.sh out/
* TODO also try non-fad words for the sources that give the best candidates
  or for high frequency candidates etc.

* TODO shorten corpora to size of the smallest for comparable frequencies?
  Currently, =canonicalise.sh= will simply divide the sum of the larger by
  the sum of the smallest corpus.

* TODO kwic-annotate out-files

* TODO run through usmjNorm and take lemmas for words marked Err/Sub ?
* TODO sub-word correspondences
  A level between the current xfst (spelling/phon) and decomp.

  Make char-gram frequency list for *correspondending pairs*,
  something like

  |    f | sme   | smj   |
  |------+-------+-------|
  | 1200 | á     | á     |
  |  391 | laš   | lasj  |
  |  341 | buvs  | båvs  |
  |  332 | hte   | hte   |
  |  201 | htit  | htet  |
  |  112 | ja    | jáv   |
  |   93 | halla | dalla |
  |   12 | áli   | állá  |
  |   12 | anb   | amb   |

  We might eventually apply the longer of these in the xfst step with
  priority union, or have a separate candidate generator using e.g.
  beam search on frequency.

  Could use moses by turning seed word-lists into sentences, so
  : adni - addne
  becomes
  : a d n i - a d d n e
  
  (though we already find compound-part correspondences with _precomp,
  maybe enough …)
* TODO moses? berkelyaligner? fastalign?
