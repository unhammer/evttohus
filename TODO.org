* TODO include anymalign results where src=fad in pretty.sh out/
* TODO compound correspondences
  decompound our existing translations from words/ and use the
  corresponding parts for the dict in compound_translate.awk

  Currently, we only use whole words from words/ in the dict in
  compound_translate.awk. So if "læreplan" is in words, we might get a
  candidate for "læreplanforslag". But "læreplan" can be decompounded
  as lære+plan, which might give a candidate for "læreverk",
  "lærested", etc.

#+BEGIN_SRC sh
  $ echo learoesoejkesje | ana sma
  learoesoejkesje learoe+N+SgNomCmp+Cmp#soejkesje+N+Sg+Nom
  learoesoejkesje learoesoejkesje+N+Sg+Nom
  
  $ echo læreplan | ana nob
  læreplan        lære+N#+Cmp+plan+N+Msc+Sg+Indef
  læreplan        læreplan+N+Msc+Sg+Indef
#+END_SRC

  Given two analyses, match any readings with the same number of compound parts, ie.
  | læreplan  | learoesoejkesje  |
  | lære+plan | learoe+soejkesje |
  and then we expand parts, giving
  | læreplan | learoesoejkesje |
  | lære     | learoe          |
  | plan     | soejkesje       |
  
* TODO also try non-fad words for the sources that give the best candidates
  or for high frequency candidates etc.

* TODO Kintel, for nobsmj
  http://gtweb.uit.no/webdict/ak/smj2nob/index.html
  

* TODO shorten corpora to size of the smallest for comparable frequencies?
  Currently, =pretty.sh= will simply divide the sum of the larger by
  the sum of the smallest corpus.

* TODO kwic-annotate out-files

* TODO run through usmjNorm and take lemmas for words marked Err/Sub ?
* TODO sub-word correspondences
  A level between the current xfst (spelling/phon) and decomp.

  Make char-gram frequency list for *correspondending pairs*,
  something like

  |    f | sme   | smj   |
  |------+-------+-------|
  | 1200 | á     | á     |
  |  391 | laš   | lasj  |
  |  341 | buvs  | båvs  |
  |  332 | hte   | hte   |
  |  201 | htit  | htet  |
  |  112 | ja    | jáv   |
  |   93 | halla | dalla |
  |   12 | áli   | állá  |
  |   12 | anb   | amb   |

  We might eventually apply the longer of these in the xfst step with
  priority union, or have a separate candidate generator using e.g.
  beam search on frequency.

  Could use moses by turning seed word-lists into sentences, so
  : adni - addne
  becomes
  : a d n i - a d d n e
  
  (though finding [[*compound%20correspondences][compound correspondences]] is probably going to give
  better results)
